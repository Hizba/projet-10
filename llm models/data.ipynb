{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53887413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6767bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"frames.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be14c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>turns</th>\n",
       "      <th>wizard_id</th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>[{'text': 'I'd like to book a trip to Atlantis...</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>{'userSurveyRating': 4.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U21E41CQP</td>\n",
       "      <td>[{'text': 'Hello, I am looking to book a vacat...</td>\n",
       "      <td>U21DMV0KA</td>\n",
       "      <td>4a3bfa39-2c22-42c8-8694-32b4e34415e9</td>\n",
       "      <td>{'userSurveyRating': 3.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U21RP4FCY</td>\n",
       "      <td>[{'text': 'Hello there i am looking to go on a...</td>\n",
       "      <td>U21E0179B</td>\n",
       "      <td>6e67ed28-e94c-4fab-96b6-68569a92682f</td>\n",
       "      <td>{'userSurveyRating': 2.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>[{'text': 'Hi I'd like to go to Caprica from B...</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>5ae76e50-5b48-4166-9f6d-67aaabd7bcaa</td>\n",
       "      <td>{'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U21E41CQP</td>\n",
       "      <td>[{'text': 'Hello, I am looking to book a trip ...</td>\n",
       "      <td>U21DMV0KA</td>\n",
       "      <td>24603086-bb53-431e-a0d8-1dcc63518ba9</td>\n",
       "      <td>{'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                              turns  wizard_id  \\\n",
       "0  U22HTHYNP  [{'text': 'I'd like to book a trip to Atlantis...  U21DKG18C   \n",
       "1  U21E41CQP  [{'text': 'Hello, I am looking to book a vacat...  U21DMV0KA   \n",
       "2  U21RP4FCY  [{'text': 'Hello there i am looking to go on a...  U21E0179B   \n",
       "3  U22HTHYNP  [{'text': 'Hi I'd like to go to Caprica from B...  U21DKG18C   \n",
       "4  U21E41CQP  [{'text': 'Hello, I am looking to book a trip ...  U21DMV0KA   \n",
       "\n",
       "                                     id  \\\n",
       "0  e2c0fc6c-2134-4891-8353-ef16d8412c9a   \n",
       "1  4a3bfa39-2c22-42c8-8694-32b4e34415e9   \n",
       "2  6e67ed28-e94c-4fab-96b6-68569a92682f   \n",
       "3  5ae76e50-5b48-4166-9f6d-67aaabd7bcaa   \n",
       "4  24603086-bb53-431e-a0d8-1dcc63518ba9   \n",
       "\n",
       "                                              labels  \n",
       "0  {'userSurveyRating': 4.0, 'wizardSurveyTaskSuc...  \n",
       "1  {'userSurveyRating': 3.0, 'wizardSurveyTaskSuc...  \n",
       "2  {'userSurveyRating': 2.0, 'wizardSurveyTaskSuc...  \n",
       "3  {'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...  \n",
       "4  {'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ea3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# df : ton DataFrame original\n",
    "\n",
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    conv_id = row[\"id\"]\n",
    "    user_id = row[\"user_id\"]\n",
    "    wizard_id = row[\"wizard_id\"]\n",
    "    for turn in row[\"turns\"]:         # chaque Ã©lÃ©ment est un dict\n",
    "        turn_copy = turn.copy()\n",
    "        turn_copy[\"conv_id\"] = conv_id\n",
    "        turn_copy[\"user_id\"] = user_id\n",
    "        turn_copy[\"wizard_id\"] = wizard_id\n",
    "        rows.append(turn_copy)\n",
    "\n",
    "turns_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db10c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_jsonl_line(turn_row):\n",
    "    if turn_row.get(\"author\") != \"user\":\n",
    "        return None\n",
    "\n",
    "    text = turn_row.get(\"text\", \"\")\n",
    "    frames = turn_row.get(\"labels\", {}).get(\"frames\", [])\n",
    "    info = frames[0].get(\"info\", {}) if frames else {}\n",
    "\n",
    "    def get_val(key):\n",
    "        arr = info.get(key, [])\n",
    "        return arr[0][\"val\"] if arr else None\n",
    "\n",
    "    intent = get_val(\"intent\")\n",
    "    or_city = get_val(\"or_city\")\n",
    "    dst_city = get_val(\"dst_city\")\n",
    "    budget = get_val(\"budget\")\n",
    "\n",
    "    output = {}\n",
    "    if intent is not None:\n",
    "        output[\"intent\"] = intent\n",
    "    if or_city is not None:\n",
    "        output[\"or_city\"] = or_city\n",
    "    if dst_city is not None:\n",
    "        output[\"dst_city\"] = dst_city\n",
    "    if budget is not None:\n",
    "        try:\n",
    "            output[\"budget\"] = float(budget)\n",
    "        except ValueError:\n",
    "            output[\"budget\"] = budget\n",
    "\n",
    "    jsonl_obj = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are an assistant that extracts flight booking information: \"\n",
    "                    \"intent, or_city, dst_city, dep_date, ret_date, budget. \"\n",
    "                    \"Always answer with a valid JSON object and nothing else.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": json.dumps(output, ensure_ascii=False)\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "    return json.dumps(jsonl_obj, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3caf02c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>author</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>conv_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wizard_id</th>\n",
       "      <th>db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to book a trip to Atlantis from Capri...</td>\n",
       "      <td>{'acts': [{'args': [{'val': 'book', 'key': 'in...</td>\n",
       "      <td>user</td>\n",
       "      <td>1.471272e+12</td>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi...I checked a few options for you, and unfo...</td>\n",
       "      <td>{'acts': [{'args': [{'val': [{'annotations': [...</td>\n",
       "      <td>wizard</td>\n",
       "      <td>1.471272e+12</td>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>{'result': [[{'trip': {'returning': {'duration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, how about going to Neverland from Caprica...</td>\n",
       "      <td>{'acts': [{'args': [{'val': 'Neverland', 'key'...</td>\n",
       "      <td>user</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I checked the availability for this date and t...</td>\n",
       "      <td>{'acts': [{'args': [{'val': [{'annotations': [...</td>\n",
       "      <td>wizard</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>{'result': [[], [], [], [], [], []], 'search':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no flexibility for dates... but I can l...</td>\n",
       "      <td>{'acts': [{'args': [{'val': False, 'key': 'fle...</td>\n",
       "      <td>user</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I'd like to book a trip to Atlantis from Capri...   \n",
       "1  Hi...I checked a few options for you, and unfo...   \n",
       "2  Yes, how about going to Neverland from Caprica...   \n",
       "3  I checked the availability for this date and t...   \n",
       "4  I have no flexibility for dates... but I can l...   \n",
       "\n",
       "                                              labels  author     timestamp  \\\n",
       "0  {'acts': [{'args': [{'val': 'book', 'key': 'in...    user  1.471272e+12   \n",
       "1  {'acts': [{'args': [{'val': [{'annotations': [...  wizard  1.471272e+12   \n",
       "2  {'acts': [{'args': [{'val': 'Neverland', 'key'...    user  1.471273e+12   \n",
       "3  {'acts': [{'args': [{'val': [{'annotations': [...  wizard  1.471273e+12   \n",
       "4  {'acts': [{'args': [{'val': False, 'key': 'fle...    user  1.471273e+12   \n",
       "\n",
       "                                conv_id    user_id  wizard_id  \\\n",
       "0  e2c0fc6c-2134-4891-8353-ef16d8412c9a  U22HTHYNP  U21DKG18C   \n",
       "1  e2c0fc6c-2134-4891-8353-ef16d8412c9a  U22HTHYNP  U21DKG18C   \n",
       "2  e2c0fc6c-2134-4891-8353-ef16d8412c9a  U22HTHYNP  U21DKG18C   \n",
       "3  e2c0fc6c-2134-4891-8353-ef16d8412c9a  U22HTHYNP  U21DKG18C   \n",
       "4  e2c0fc6c-2134-4891-8353-ef16d8412c9a  U22HTHYNP  U21DKG18C   \n",
       "\n",
       "                                                  db  \n",
       "0                                                NaN  \n",
       "1  {'result': [[{'trip': {'returning': {'duration...  \n",
       "2                                                NaN  \n",
       "3  {'result': [[], [], [], [], [], []], 'search':...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appliquer la fonction sur chaque ligne de turns_df\n",
    "turns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd98a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer la fonction sur chaque ligne de turns_df\n",
    "turns_df[\"jsonl_line\"] = turns_df.apply(turn_to_jsonl_line, axis=1)\n",
    "\n",
    "# garder seulement les lignes non nulles (tours user)\n",
    "jsonl_lines = turns_df[\"jsonl_line\"].dropna()\n",
    "\n",
    "# Ã©crire le fichier pour le fine-tuning\n",
    "with open(\"train.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in jsonl_lines:\n",
    "        f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f0686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"LiquidAI/LFM2.5-1.2B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",       # \"cpu\" si tu n'as pas de GPU\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467b1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an assistant that extracts flight booking information: \"\n",
    "            \"intent, or_city, dst_city, dep_date, ret_date, budget. \"\n",
    "            \"Always answer with a valid JSON object and nothing else.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello, I am looking to book a vacation from Gotham City to Mos Eisley for $2100.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3678297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": \"book_flight\",\n",
      "  \"or_city\": \"Gotham City\",\n",
      "  \"dst_city\": \"Mos Eisley\",\n",
      "  \"dep_date\": \"2023-11-15\",\n",
      "  \"ret_date\": \"2023-11-20\",\n",
      "  \"budget\": \"2100\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_k=50,\n",
    "        top_p=0.1,\n",
    "        repetition_penalty=1.05,\n",
    "    )\n",
    "\n",
    "generated = tokenizer.decode(output_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bb7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 89.76ba/s]\n",
      "Creating json from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 103.54ba/s]\n",
      "Creating json from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 116.54ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "863705"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ALL_PATH = \"all.jsonl\"\n",
    "\n",
    "ds = load_dataset(\"json\", data_files=ALL_PATH, split=\"train\")\n",
    "\n",
    "# MÃ©langer\n",
    "ds = ds.shuffle(seed=42)\n",
    "\n",
    "# Split 80% train, 20% test\n",
    "split = ds.train_test_split(test_size=0.2, seed=42)\n",
    "ds_train = split[\"train\"]\n",
    "ds_test  = split[\"test\"]\n",
    "\n",
    "# (Option) garder une petite validation Ã  partir du train\n",
    "valid_split = ds_train.train_test_split(test_size=0.1, seed=42)\n",
    "ds_train = valid_split[\"train\"]\n",
    "ds_val   = valid_split[\"test\"]\n",
    "\n",
    "# Sauvegarder en JSONL si tu veux des fichiers sÃ©parÃ©s\n",
    "ds_train.to_json(\"train.jsonl\", lines=True, orient=\"records\")\n",
    "ds_val.to_json(\"val.jsonl\", lines=True, orient=\"records\")\n",
    "ds_test.to_json(\"test.jsonl\", lines=True, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82306e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 7492 examples [00:00, 811563.16 examples/s]\n",
      "Generating train split: 833 examples [00:00, 152264.24 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7492/7492 [00:03<00:00, 2218.31 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 833/833 [00:00<00:00, 2132.94 examples/s]\n",
      "C:\\Users\\Rafik\\AppData\\Local\\Temp\\ipykernel_4708\\88741086.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "d:\\haythem_gassab\\projet 10\\flyme-chat-widget-test\\mock-backend\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "MODEL_ID   = \"LiquidAI/LFM2.5-1.2B-Instruct\"\n",
    "TRAIN_PATH = \"train.jsonl\"\n",
    "VAL_PATH   = \"val.jsonl\"\n",
    "OUTPUT_DIR = \"lfm2_finetuned_flyme\"\n",
    "MAX_LEN    = 512\n",
    "\n",
    "# 1) Charger datasets\n",
    "ds_train = load_dataset(\"json\", data_files=TRAIN_PATH, split=\"train\")\n",
    "ds_val   = load_dataset(\"json\", data_files=VAL_PATH,   split=\"train\")\n",
    "\n",
    "# 2) Tok + modÃ¨le\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# 3) PrÃ©-traitement robuste\n",
    "def preprocess(example):\n",
    "    messages = example[\"messages\"]\n",
    "\n",
    "    # texte complet (system + user + assistant)\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",   # TOUTES les sÃ©quences auront MAX_LEN\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "    # labels = input_ids, mÃªme taille\n",
    "    enc[\"labels\"] = enc[\"input_ids\"].copy()\n",
    "\n",
    "    # on ne garde que les colonnes utiles\n",
    "    return {\n",
    "        \"input_ids\": enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"],\n",
    "        \"labels\": enc[\"labels\"],\n",
    "    }\n",
    "\n",
    "ds_train_tok = ds_train.map(preprocess, batched=False)\n",
    "ds_val_tok   = ds_val.map(preprocess,   batched=False)\n",
    "\n",
    "# 4) Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train_tok,\n",
    "    eval_dataset=ds_val_tok,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8035534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Map:   0%|          | 0/200 [00:00<?, ? examples/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:52<00:00,  4.16s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent accuracy : 0.0\n",
      "Exact match     : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# ModÃ¨le open (pas de gated repo)\n",
    "MODEL_ID  = \"LiquidAI/LFM2-350M-Extract\"  # 350M, spÃ©cialisÃ© extraction\n",
    "TEST_PATH = \"test.jsonl\"\n",
    "\n",
    "# 1) Charger modÃ¨le + tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# 2) Charger dataset de test\n",
    "ds_test = load_dataset(\"json\", data_files=TEST_PATH, split=\"train\")\n",
    "\n",
    "def eval_example(example):\n",
    "    messages = example[\"messages\"]\n",
    "\n",
    "    # JSON de rÃ©fÃ©rence = dernier message assistant\n",
    "    ref_str = messages[-1][\"content\"]\n",
    "    try:\n",
    "        ref_json = json.loads(ref_str)\n",
    "    except Exception:\n",
    "        return {\"exact_match\": 0.0, \"intent_correct\": 0.0}\n",
    "\n",
    "    # system + user uniquement pour la prÃ©diction\n",
    "    eval_messages = messages[:-1]\n",
    "\n",
    "    # Prompt renforcÃ© avec exemple\n",
    "    system_content = (\n",
    "        \"You are an assistant that extracts flight booking information \"\n",
    "        \"from the user's message and returns a JSON object.\\n\"\n",
    "        \"Fields: intent, or_city, dst_city, dep_date, ret_date, budget.\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"User: I want to book a flight from Gotham City to Mos Eisley from November 15th to November 20th with a budget of 2100 dollars.\\n\"\n",
    "        \"Assistant: {\\\"intent\\\": \\\"book_flight\\\", \\\"or_city\\\": \\\"Gotham City\\\", \\\"dst_city\\\": \\\"Mos Eisley\\\", \\\"dep_date\\\": \\\"2023-11-15\\\", \\\"ret_date\\\": \\\"2023-11-20\\\", \\\"budget\\\": \\\"2100\\\"}\\n\\n\"\n",
    "        \"Now extract the JSON for the following user message.\"\n",
    "    )\n",
    "\n",
    "    if len(eval_messages) > 0 and eval_messages[0][\"role\"] == \"system\":\n",
    "        eval_messages[0][\"content\"] = system_content\n",
    "    else:\n",
    "        eval_messages = [{\"role\": \"system\", \"content\": system_content}] + eval_messages\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        eval_messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n",
    "    gen_text = tokenizer.decode(\n",
    "        output_ids[0][inputs[\"input_ids\"].shape[1]:],\n",
    "        skip_special_tokens=True,\n",
    "    ).strip()\n",
    "\n",
    "    # Nettoyer pour ne garder que le JSON\n",
    "    start = gen_text.find(\"{\")\n",
    "    end = gen_text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        gen_text_clean = gen_text[start:end+1]\n",
    "    else:\n",
    "        gen_text_clean = gen_text\n",
    "\n",
    "    try:\n",
    "        pred_json = json.loads(gen_text_clean)\n",
    "    except Exception:\n",
    "        return {\"exact_match\": 0.0, \"intent_correct\": 0.0}\n",
    "\n",
    "    intent_correct = float(pred_json.get(\"intent\") == ref_json.get(\"intent\"))\n",
    "\n",
    "    keys = [\"intent\", \"or_city\", \"dst_city\", \"dep_date\", \"ret_date\", \"budget\"]\n",
    "    exact = float(all(pred_json.get(k) == ref_json.get(k) for k in keys))\n",
    "\n",
    "    return {\"exact_match\": exact, \"intent_correct\": intent_correct}\n",
    "\n",
    "# 4) Ã‰valuation\n",
    "ds_eval = ds_test.select(range(200))  # 200 exemples pour aller vite\n",
    "results = ds_eval.map(eval_example)\n",
    "\n",
    "exact_match_score = sum(results[\"exact_match\"]) / len(results)\n",
    "intent_acc        = sum(results[\"intent_correct\"]) / len(results)\n",
    "\n",
    "print(\"Intent accuracy :\", intent_acc)\n",
    "print(\"Exact match     :\", exact_match_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "930935d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_example(example):\n",
    "    messages = example[\"messages\"]\n",
    "\n",
    "    # JSON de rÃ©fÃ©rence\n",
    "    ref_str = messages[-1][\"content\"]\n",
    "    try:\n",
    "        ref_json = json.loads(ref_str)\n",
    "    except Exception:\n",
    "        return {\"exact_match\": 0.0, \"intent_correct\": 0.0}\n",
    "\n",
    "    eval_messages = messages[:-1]\n",
    "\n",
    "    # System renforcÃ©\n",
    "    system_content = (\n",
    "        \"You are an assistant that extracts flight booking information \"\n",
    "        \"from the user's message and returns a JSON object.\\n\"\n",
    "        \"Fields: intent, or_city, dst_city, dep_date, ret_date, budget.\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"User: I want to book a flight from Gotham City to Mos Eisley from November 15th to November 20th with a budget of 2100 dollars.\\n\"\n",
    "        \"Assistant: {\\\"intent\\\": \\\"book_flight\\\", \\\"or_city\\\": \\\"Gotham City\\\", \\\"dst_city\\\": \\\"Mos Eisley\\\", \\\"dep_date\\\": \\\"2023-11-15\\\", \\\"ret_date\\\": \\\"2023-11-20\\\", \\\"budget\\\": \\\"2100\\\"}\\n\\n\"\n",
    "        \"Now extract the JSON for the following user message.\"\n",
    "    )\n",
    "\n",
    "    if len(eval_messages) > 0 and eval_messages[0][\"role\"] == \"system\":\n",
    "        eval_messages[0][\"content\"] = system_content\n",
    "    else:\n",
    "        eval_messages = [{\"role\": \"system\", \"content\": system_content}] + eval_messages\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        eval_messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    \n",
    "    # DEBUG : afficher le prompt et la phrase\n",
    "    print(\"=== DEBUG ===\")\n",
    "    print(\"User message :\", eval_messages[-1][\"content\"])\n",
    "    print(\"Prompt envoyÃ© :\", prompt[:200] + \"...\")\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n",
    "    gen_text = tokenizer.decode(\n",
    "        output_ids[0][inputs[\"input_ids\"].shape[1]:],\n",
    "        skip_special_tokens=True,\n",
    "    ).strip()\n",
    "\n",
    "    # DEBUG : afficher la gÃ©nÃ©ration brute\n",
    "    print(\"GÃ©nÃ©ration brute :\", repr(gen_text))\n",
    "    print(\"=================\")\n",
    "\n",
    "    # Nettoyer pour JSON\n",
    "    start = gen_text.find(\"{\")\n",
    "    end = gen_text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        gen_text_clean = gen_text[start:end+1]\n",
    "    else:\n",
    "        gen_text_clean = gen_text\n",
    "\n",
    "    print(\"JSON nettoyÃ© :\", repr(gen_text_clean))\n",
    "\n",
    "    try:\n",
    "        pred_json = json.loads(gen_text_clean)\n",
    "        print(\"JSON parsÃ© :\", pred_json)\n",
    "    except Exception as e:\n",
    "        print(\"Erreur parsing :\", e)\n",
    "        return {\"exact_match\": 0.0, \"intent_correct\": 0.0}\n",
    "\n",
    "    # Comparaison\n",
    "    intent_correct = float(pred_json.get(\"intent\") == ref_json.get(\"intent\"))\n",
    "    keys = [\"intent\", \"or_city\", \"dst_city\", \"dep_date\", \"ret_date\", \"budget\"]\n",
    "    exact = float(all(pred_json.get(k) == ref_json.get(k) for k in keys))\n",
    "\n",
    "    print(\"Ref JSON :\", ref_json)\n",
    "    print(\"Intent OK :\", intent_correct)\n",
    "    print(\"Exact match :\", exact)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return {\"exact_match\": exact, \"intent_correct\": intent_correct}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b53306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent accuracy : 0.0\n",
      "Exact match     : 0.0\n"
     ]
    }
   ],
   "source": [
    "ds_eval = ds_test.select(range(3))  # juste 3 exemples\n",
    "results = ds_eval.map(eval_example)\n",
    "\n",
    "exact_match_score = sum(results[\"exact_match\"]) / len(results)\n",
    "intent_acc        = sum(results[\"intent_correct\"]) / len(results)\n",
    "\n",
    "print(\"Intent accuracy :\", intent_acc)\n",
    "print(\"Exact match     :\", exact_match_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cda2f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  SMART AGENT v2 - Stateful LLM\n",
      "============================================================\n",
      "\n",
      "ðŸ‘¤ YOU: I need a hotel\n",
      "ðŸ¤– BOT: {\"or_city\": \"New York\"}\n",
      "\n",
      "Summary: You are looking for a hotel in New York.  \n",
      "Confirm?\n",
      "ðŸ“Š STATUS: NEEDS_4_MORE_FIELDS\n",
      "ðŸ“‹ STATE: {'intent': None, 'or_city': 'New York', 'dst_city': None, 'dep_date': None, 'ret_date': None, 'budget': None, 'status': 'waiting_intent'}\n",
      "\n",
      "ðŸ‘¤ YOU: Book flight Paris to NYC $800\n",
      "ðŸ¤– BOT: {\"intent\": \"book_flight\", \"or_city\": \"Paris\", \"dep_date\": null, \"ret_date\": null, \"budget\": 800, \"status\": \"waiting_intent\"}\n",
      "ðŸ“Š STATUS: NEEDS_3_MORE_FIELDS\n",
      "ðŸ“‹ STATE: {'intent': 'book_flight', 'or_city': 'Paris', 'dst_city': None, 'dep_date': None, 'ret_date': None, 'budget': 800, 'status': 'waiting_intent'}\n",
      "\n",
      "ðŸ‘¤ YOU: November 15-20\n",
      "ðŸ¤– BOT: {\"intent\": \"book_flight\", \"or_city\": \"Paris\", \"dep_date\": \"2023-11-15\", \"ret_date\": \"2023-11-20\", \"budget\": 800, \"status\": \"waiting_intent\"}\n",
      "ðŸ“Š STATUS: NEEDS_1_MORE_FIELDS\n",
      "ðŸ“‹ STATE: {'intent': 'book_flight', 'or_city': 'Paris', 'dst_city': None, 'dep_date': '2023-11-15', 'ret_date': '2023-11-20', 'budget': 800, 'status': 'waiting_intent'}\n",
      "\n",
      "ðŸ‘¤ YOU: Yes book it\n",
      "ðŸ¤– BOT: {\"intent\": \"book_flight\", \"or_city\": \"Paris\", \"dep_date\": \"2023-11-15\", \"ret_date\": \"2023-11-20\", \"budget\": 800, \"status\": \"confirmed\"}\n",
      "ðŸ“Š STATUS: NEEDS_1_MORE_FIELDS\n",
      "ðŸ“‹ STATE: {'intent': 'book_flight', 'or_city': 'Paris', 'dst_city': None, 'dep_date': '2023-11-15', 'ret_date': '2023-11-20', 'budget': 800, 'status': 'confirmed'}\n",
      "\n",
      "âœ… Smart Agent v2 ready!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import Dict, Any\n",
    "\n",
    "MODEL_ID = \"LiquidAI/LFM2.5-1.2B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, device_map=\"auto\")\n",
    "\n",
    "class SmartFlightAgent:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.state: Dict[str, Any] = {\n",
    "            \"intent\": None,\n",
    "            \"or_city\": None,\n",
    "            \"dst_city\": None,\n",
    "            \"dep_date\": None,\n",
    "            \"ret_date\": None,\n",
    "            \"budget\": None,\n",
    "            \"status\": \"waiting_intent\"  # waiting_intent, collecting_info, ready_confirm\n",
    "        }\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        # Build full context\n",
    "        response = self._get_agent_response(user_message)\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _get_agent_response(self, message: str) -> str:\n",
    "        system_prompt = self._build_system_prompt()\n",
    "        \n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + self.conversation_history[-4:]\n",
    "        \n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=150,\n",
    "                temperature=0.1,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        full_response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "        \n",
    "        # Parse structured response\n",
    "        self._parse_and_update(full_response)\n",
    "        \n",
    "        return full_response\n",
    "    \n",
    "    def _build_system_prompt(self) -> str:\n",
    "        state_str = json.dumps(self.state, indent=2)\n",
    "        return f\"\"\"FLIGHT BOOKING AGENT v2\n",
    "\n",
    "Current state:\n",
    "{state_str}\n",
    "\n",
    "RULES (IMPORTANT):\n",
    "1. ONLY flights. \"hotel/car\" â†’ \"I only book flights\"\n",
    "2. Extract ONLY explicit info. NO guessing dates/cities\n",
    "3. Ask ONE missing field at a time  \n",
    "4. When complete â†’ Summary + confirm\n",
    "5. Update state in JSON format first line\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Line 1: JSON state update\n",
    "Line 2+: Human response\n",
    "\n",
    "Example:\n",
    "{{\"or_city\": \"Paris\"}}\n",
    "Perfect! Where to?\"\"\"\n",
    "\n",
    "    def _parse_and_update(self, response: str):\n",
    "        \"\"\"Parse JSON from first line, update state\"\"\"\n",
    "        lines = response.strip().split('\\n')\n",
    "        if lines:\n",
    "            json_line = lines[0].strip()\n",
    "            try:\n",
    "                update = json.loads(json_line)\n",
    "                self.state.update({k: v for k, v in update.items() if v is not None})\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    \n",
    "    def get_status(self) -> str:\n",
    "        missing = sum(1 for v in [self.state[k] for k in ['or_city','dst_city','dep_date','ret_date','budget']] if not v)\n",
    "        if missing == 0:\n",
    "            return \"READY_TO_CONFIRM\"\n",
    "        return f\"NEEDS_{missing}_MORE_FIELDS\"\n",
    "\n",
    "# =====================================================\n",
    "# TEST NOUVELLE ROUTINE\n",
    "# =====================================================\n",
    "agent = SmartFlightAgent()\n",
    "\n",
    "print(\"ðŸ§  SMART AGENT v2 - Stateful LLM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_convo = [\n",
    "    \"I need a hotel\",\n",
    "    \"Book flight Paris to NYC $800\", \n",
    "    \"November 15-20\",\n",
    "    \"Yes book it\"\n",
    "]\n",
    "\n",
    "for msg in test_convo:\n",
    "    print(f\"\\nðŸ‘¤ YOU: {msg}\")\n",
    "    response = agent.chat(msg)\n",
    "    print(f\"ðŸ¤– BOT: {response}\")\n",
    "    print(f\"ðŸ“Š STATUS: {agent.get_status()}\")\n",
    "    print(f\"ðŸ“‹ STATE: {agent.state}\")\n",
    "\n",
    "print(\"\\nâœ… Smart Agent v2 ready!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
